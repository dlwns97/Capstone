{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modular.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-FnrHKo6cHmaCwaud4aWHuiqVz5gyfhc","authorship_tag":"ABX9TyNIV+wwUWtmnHN0hHUXKG+N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"w-DBib3gLs5a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49e422f0-70b7-4bc3-c70c-12fb4ae9f79e","executionInfo":{"status":"ok","timestamp":1655414068573,"user_tz":-540,"elapsed":6463,"user":{"displayName":"조이준","userId":"01098056164953753819"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["count:  100\n","score:  150\n"]}],"source":["# 필요 라이브러리 정의\n","import os\n","\n","import torchvision.models as models\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import load_img \n","\n","\n","import collections\n","from sklearn.cluster import KMeans\n","\n","\n","def GetDLModel():\n","  # load the pretreained Resnet model\n","  # 모델 불러와서 일부 키 값 resnet50 model에 맞게 수정\n","\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","\n","\n","  checkpoint2 = torch.load('/content/drive/MyDrive/resnet50_market_xent.pth.tar', map_location=device, encoding='latin1')\n","  checkpoint2['state_dict']['fc.weight'] = checkpoint2['state_dict'].pop('classifier.weight')\n","  checkpoint2['state_dict']['fc.bias'] = checkpoint2['state_dict'].pop('classifier.bias')\n","\n","  # 기존의 resnet50을 market1501을 학습 시킨 모델과 출력층이 동일하게 구성\n","  res2 = models.resnet50()\n","  x = res2.fc.weight\n","  x = torch.narrow(x, 0, 0, 751)\n","  y = res2.fc.bias\n","  y = torch.narrow(y, 0, 0, 751)\n","\n","  res2.fc.weight = nn.Parameter(x)\n","  res2.fc.bias = nn.Parameter(y)\n","  res2.fc.out_features=751\n","\n","  # 모델 덮어 씌우기\n","  res2.load_state_dict(checkpoint2['state_dict'])\n","  res2.to(device) # 가중치를 GPU 계산과 CPU 계산 중 하나로 통일\n","\n","  return res2\n","\n","def getImages():\n","  # 이미지 폴더에서 이미지 셋 리스트에 저장\n","\n","  # PATH of Cropped and target images\n","  path = '/content/drive/MyDrive/ZEPETO2'\n","  os.chdir(path)\n","\n","  images = []\n","\n","  # 이미지 파일 리스트에 삽입\n","  with os.scandir(path) as files:\n","      for file in files:\n","          if file.name.endswith('.png'):\n","              images.append(file.name)\n","  return images\n","\n","# Bulid feature extractor class by using pretained resnet\n","# feature extractor class 설계\n","class FeatureExtractor(nn.Module):\n","  def __init__(self, model):\n","    super(FeatureExtractor, self).__init__()\n","    self.conv1 = model.conv1\n","    self.bn1 = model.bn1\n","    self.relu = model.relu\n","    self.maxpool = model.maxpool\n","    self.layer1 = model.layer1\n","    self.layer2 = model.layer2\n","    self.layer3 = model.layer3\n","    self.layer4 = model.layer4\n","    self.global_avgpool = model.avgpool\n","    self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n","    return\n","  def featuremaps(self, x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.maxpool(x)\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","    return x\n","  def forward(self, x):\n","    f = self.featuremaps(x)\n","    v = self.global_avgpool(f)\n","    v = v.view(v.size(0), -1)\n","    v = self.pool(v)\n","    v = self.pool(v)\n","    v = self.pool(v)\n","    #v = self.pool(v)\n","    #v = self.pool(v)\n","    #v = self.pool(v)\n","    return v\n","  \n","# 이미지 특징 추출 함수\n","def extracting_feature(model, images, target_name, transform):\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","  features_ = []\n","  extract_feature = FeatureExtractor(model)\n","  for i in range(len(images)):\n","    if i==len(images):\n","      break\n","    path = os.path.join('/content/drive/MyDrive/ZEPETO2', images[i])\n","    img = load_img(path, target_size=(224,224))\n","    img = np.array(img)\n","    img = transform(img)\n","    img = img.reshape(1, 3, 224, 224)\n","    img = img.to(device)\n","    with torch.no_grad():\n","      feature = extract_feature(img)\n","    features_.append(feature.cpu().detach().numpy().reshape(-1))\n","  return features_\n","  \n","def clusters(feat, n_clusters=10):\n","  kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=5, max_iter=300, random_state=0)\n","  kmeans.fit(feat)\n","  result = kmeans.labels_\n","  labels = np.unique(result)\n","  return result, labels  \n","\n","\n","# 이미지 transform 구성\n","def get_transform():\n","  transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                              \n","  ])\n","  return transform\n","\n","def play(n_cluster=3, image_name=['target.png']):\n","  target_name = image_name\n","  MyResnet = GetDLModel()\n","  zepeto = getImages()\n","  trans = get_transform()\n","  features = extracting_feature(MyResnet, zepeto, target_name, trans)\n","  features = np.array(features)\n","  (res, labels) = clusters(features, 3)\n","\n","  groups = {}\n","  for file, cluster in zip(zepeto,res):\n","      if cluster not in groups.keys():\n","          groups[cluster] = []\n","          groups[cluster].append(file)\n","      else:\n","          groups[cluster].append(file)\n","  count=0\n","  for i in range(len(labels)):\n","    flag=0\n","    for target in target_name:\n","      if target in groups[i]:\n","        flag=1\n","        break\n","    if flag==0:\n","      count+=len(groups[i])   \n","  return count\n","\n","cnt = play(3,['target.png'])\n","print('count: ',cnt)\n","score = 0\n","if cnt < 20:\n","  score=20\n","elif cnt<50:\n","  score=50\n","elif cnt<80:\n","  score=80\n","elif cnt<100:\n","  score=100\n","elif cnt<150:\n","  score=150\n","else:\n","  score=200\n","print('score: ', score)\n","#return score"]},{"cell_type":"code","source":["  '''\n","  군집화 결과 검증 코드\n","  import matplotlib.pyplot as plt\n","  def view_cluster(groups, cluster):\n","    plt.figure(figsize = (25,25));\n","    # gets the list of filenames for a cluster\n","    files = groups[cluster]\n","    # only allow up to 30 images to be shown at a time\n","    if len(files) > 20:\n","        print(f\"Clipping cluster size from {len(files)} to 20\")\n","        files = files[:19]\n","    # plot each image in the cluster\n","    for index, file in enumerate(files):\n","        plt.subplot(10,10,index+1);\n","        img = load_img(file)\n","        img = np.array(img)\n","        plt.imshow(img)\n","        plt.axis('off')\n","  for item in labels:\n","    if item==-1:\n","      continue\n","    print(f'image in {item} cluster')\n","    view_cluster(groups,item)\n","    plt.show()\n","    '''"],"metadata":{"id":"mfXHMam-uqS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FZh1c2dbWddn"},"execution_count":null,"outputs":[]}]}